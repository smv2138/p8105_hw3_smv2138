---
title: "Homework 3"
output: github_document
author: Sushupta Vijapur
---
```{r setup}
library(tidyverse)
library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = 0.6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

## all plots i make will have the viridis color palette
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

```


## Problem 1

Load "instacart" dataset

```{r}
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and ... columns 

Observations are the level of itesm in the order by users. There are user / order variables -- user id, order id, order day and order hour. There are also item variables -- name, aisle, department and some numeric codes.

### Part 1
How many aisles and which are the most items from?

```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

### Part 2
Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. Arrange aisles sensibly, and organize your plot so others can read it.
Counting produces a dataframe that we can manipulate

Notes for me: 
We want to rotate axis labels because they're all overlapping 
Order from least to most number of orders (change aisle to a factor)
  "aisle = fct_reorder(aisle, n)" reorder aisle by n
```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

### Part 3
Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. Include the number of times each item is ordered in your table.

Notes for me:
To do a ranking that is different for each aisle, we need to group first
Putting group_by before count is important because in the output we will retain the aisle. So it will count the n BY the aisle.
```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(desc(aisle, rank)) %>% 
  knitr::kable()
  
```

### Part 4
Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers

```{r}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```

## Problem 2

### Part 1

```{r}
accel_data = 
  read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>%
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity_count",
    values_to = "min_of_day"
  ) %>% 
  mutate(
    min_of_day_num = as.numeric(min_of_day),
    day_type = ifelse(day == "Saturday" | day == "Sunday", "weekend", "weekday")
  )
```
The results dataframe has `r nrow(accel_data)` rows and `r ncol(accel_data)` columns. The data frame includes week, day_id and day of the week variables. I used the day variable to create a day_type variable which indicates whether it is a weekday or a weekend. Furthermore, I pivoted the activity counts and minutes variables to longer. Now there is an activity count and min of the day variable in tidy format.


### Part 2

```{r}
accel_data %>% 
  group_by(day) %>% 
  mean(min_of_day)
```

groupby and summarize problem
make sure day of the week is in the order you want it to be 
Part 3
24 hours of activity looks like in each minute in each day
min on x activity count on y. color is day of the week
geom_line might work better than a scatter


## Problem 3

Part 1
separate the date variable into 3 parts (day, month, year)
use count

Part 2
collection of data mani followed by a plotting step
group by and summarize problem 
groupby station, year, month and the summarize avg max temp
will need to filter for onlt january and july

Part 3
patchwork
one is scatter plot maybe? or contour or hex plot
one is box, violin 